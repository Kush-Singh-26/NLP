{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a16a706",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3648e80f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:09.584640Z",
     "iopub.status.busy": "2025-05-09T16:18:09.583816Z",
     "iopub.status.idle": "2025-05-09T16:18:18.068499Z",
     "shell.execute_reply": "2025-05-09T16:18:18.067774Z",
     "shell.execute_reply.started": "2025-05-09T16:18:09.584614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52a15fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:18.070290Z",
     "iopub.status.busy": "2025-05-09T16:18:18.069792Z",
     "iopub.status.idle": "2025-05-09T16:18:18.320076Z",
     "shell.execute_reply": "2025-05-09T16:18:18.319325Z",
     "shell.execute_reply.started": "2025-05-09T16:18:18.070265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2025a30c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:18.321397Z",
     "iopub.status.busy": "2025-05-09T16:18:18.321044Z",
     "iopub.status.idle": "2025-05-09T16:18:18.487527Z",
     "shell.execute_reply": "2025-05-09T16:18:18.486600Z",
     "shell.execute_reply.started": "2025-05-09T16:18:18.321369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/twitter-airline-sentiment/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee7674f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:18.490027Z",
     "iopub.status.busy": "2025-05-09T16:18:18.489777Z",
     "iopub.status.idle": "2025-05-09T16:18:18.495113Z",
     "shell.execute_reply": "2025-05-09T16:18:18.494179Z",
     "shell.execute_reply.started": "2025-05-09T16:18:18.490007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) # removes any url\n",
    "    text = re.sub(r\"@\\w+\", \"\", text) # removes any mentions like @username\n",
    "    text = re.sub(r\"[^a-zA-Z']\", \" \", text) # removes all non alphabets and apostrophe with blank\n",
    "    text = text.lower()\n",
    "    return word_tokenize(text) # tokenizes the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2cadb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:18.496115Z",
     "iopub.status.busy": "2025-05-09T16:18:18.495898Z",
     "iopub.status.idle": "2025-05-09T16:18:20.012971Z",
     "shell.execute_reply": "2025-05-09T16:18:20.012229Z",
     "shell.execute_reply.started": "2025-05-09T16:18:18.496097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(preprocess)\n",
    "label_map = {'negative':0, 'neutral':1, 'positive':2}\n",
    "df['labels'] = df['airline_sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53529670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:20.014104Z",
     "iopub.status.busy": "2025-05-09T16:18:20.013841Z",
     "iopub.status.idle": "2025-05-09T16:18:20.048916Z",
     "shell.execute_reply": "2025-05-09T16:18:20.047977Z",
     "shell.execute_reply.started": "2025-05-09T16:18:20.014086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>[what, said]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[plus, you, 've, added, commercials, to, the, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>[i, did, n't, today, must, mean, i, need, to, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[it, 's, really, aggressive, to, blast, obnoxi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[and, it, 's, a, really, big, bad, thing, abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)   \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)   \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)   \n",
       "\n",
       "                                              tokens  labels  \n",
       "0                                       [what, said]       1  \n",
       "1  [plus, you, 've, added, commercials, to, the, ...       2  \n",
       "2  [i, did, n't, today, must, mean, i, need, to, ...       1  \n",
       "3  [it, 's, really, aggressive, to, blast, obnoxi...       0  \n",
       "4  [and, it, 's, a, really, big, bad, thing, abou...       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29fd754b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:20.050106Z",
     "iopub.status.busy": "2025-05-09T16:18:20.049857Z",
     "iopub.status.idle": "2025-05-09T16:18:20.176950Z",
     "shell.execute_reply": "2025-05-09T16:18:20.176013Z",
     "shell.execute_reply.started": "2025-05-09T16:18:20.050087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter # to count how many times each item appears in a list\n",
    "\n",
    "all_tokens = [token for tokens in df['tokens'] for token in tokens] # flattens out all tokens into one big list\n",
    "vocab = {word: i+2 for i, (word, _) in enumerate(Counter(all_tokens).most_common(10000))} # creates dictionary that maps 10,000 most fequent words to unique integer.\n",
    "# first 2 indexes are reserved for padding and unknown words\n",
    "vocab['<PAD>'] = 0\n",
    "vocab['<UNK>'] = 1\n",
    "\n",
    "def encode(tokens):\n",
    "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "\n",
    "df['input_ids'] = df['tokens'].apply(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beda8493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:20.178220Z",
     "iopub.status.busy": "2025-05-09T16:18:20.177902Z",
     "iopub.status.idle": "2025-05-09T16:18:20.183420Z",
     "shell.execute_reply": "2025-05-09T16:18:20.182637Z",
     "shell.execute_reply.started": "2025-05-09T16:18:20.178196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.inputs[idx]\n",
    "        y = self.labels[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61808bc-6163-4184-b0e2-a80e8aed569a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:20.184632Z",
     "iopub.status.busy": "2025-05-09T16:18:20.184349Z",
     "iopub.status.idle": "2025-05-09T16:18:20.205790Z",
     "shell.execute_reply": "2025-05-09T16:18:20.204934Z",
     "shell.execute_reply.started": "2025-05-09T16:18:20.184613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    inputs, labels = zip(*batch) # batch = list of pairs (input_tensor, label) is separated into 2 tupples\n",
    "    lengths = [len(x) for x in inputs]\n",
    "    padded = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0) # pads all the inut sequences to the ...\n",
    "    # length of the longest one by adding 0 at end\n",
    "    return padded, torch.tensor(labels), torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4270b5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:20.208844Z",
     "iopub.status.busy": "2025-05-09T16:18:20.208604Z",
     "iopub.status.idle": "2025-05-09T16:18:20.233963Z",
     "shell.execute_reply": "2025-05-09T16:18:20.232924Z",
     "shell.execute_reply.started": "2025-05-09T16:18:20.208827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df['input_ids'], df['labels'], test_size = 0.2)\n",
    "\n",
    "train_dataset = TweetDataset(list(X_train), list(y_train))\n",
    "val_dataset = TweetDataset(list(X_val), list(y_val))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=pad_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, collate_fn=pad_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e945a051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:20.235549Z",
     "iopub.status.busy": "2025-05-09T16:18:20.234970Z",
     "iopub.status.idle": "2025-05-09T16:18:20.242538Z",
     "shell.execute_reply": "2025-05-09T16:18:20.241780Z",
     "shell.execute_reply.started": "2025-05-09T16:18:20.235525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (h_n, _) = self.lstm(packed)\n",
    "        out = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c94fd4ed-2475-47fb-927a-64dac9208602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:20.243782Z",
     "iopub.status.busy": "2025-05-09T16:18:20.243492Z",
     "iopub.status.idle": "2025-05-09T16:18:23.786073Z",
     "shell.execute_reply": "2025-05-09T16:18:23.785106Z",
     "shell.execute_reply.started": "2025-05-09T16:18:20.243762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBED_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 3  # For 3 sentiment classes\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1769e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:23.787825Z",
     "iopub.status.busy": "2025-05-09T16:18:23.787191Z",
     "iopub.status.idle": "2025-05-09T16:18:23.793542Z",
     "shell.execute_reply": "2025-05-09T16:18:23.792639Z",
     "shell.execute_reply.started": "2025-05-09T16:18:23.787795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for x, y, lengths in dataloader:\n",
    "        x, y, lengths = x.to(device), y.to(device), lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x, lengths)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "\n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    return total_loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d9049ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:18:23.794943Z",
     "iopub.status.busy": "2025-05-09T16:18:23.794615Z",
     "iopub.status.idle": "2025-05-09T16:18:23.822920Z",
     "shell.execute_reply": "2025-05-09T16:18:23.821986Z",
     "shell.execute_reply.started": "2025-05-09T16:18:23.794917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, lengths in dataloader:\n",
    "            x, y, lengths = x.to(device), y.to(device), lengths.to(device)\n",
    "\n",
    "            outputs = model(x, lengths)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "\n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    return total_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca261bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:22:31.488753Z",
     "iopub.status.busy": "2025-05-09T16:22:31.488061Z",
     "iopub.status.idle": "2025-05-09T16:23:32.800843Z",
     "shell.execute_reply": "2025-05-09T16:23:32.799983Z",
     "shell.execute_reply.started": "2025-05-09T16:22:31.488728Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.0313, Accuracy: 0.9914\n",
      "Val   Loss: 1.1677, Accuracy: 0.7534\n",
      "Epoch 2\n",
      "Train Loss: 0.0313, Accuracy: 0.9914\n",
      "Val   Loss: 1.1677, Accuracy: 0.7534\n",
      "Epoch 3\n",
      "Train Loss: 0.0313, Accuracy: 0.9914\n",
      "Val   Loss: 1.1677, Accuracy: 0.7534\n",
      "Epoch 4\n",
      "Train Loss: 0.0313, Accuracy: 0.9914\n",
      "Val   Loss: 1.1677, Accuracy: 0.7534\n",
      "Epoch 5\n",
      "Train Loss: 0.0313, Accuracy: 0.9914\n",
      "Val   Loss: 1.1677, Accuracy: 0.7534\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52c1cf65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:23:32.802460Z",
     "iopub.status.busy": "2025-05-09T16:23:32.802205Z",
     "iopub.status.idle": "2025-05-09T16:23:32.818400Z",
     "shell.execute_reply": "2025-05-09T16:23:32.817273Z",
     "shell.execute_reply.started": "2025-05-09T16:23:32.802442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/kaggle/working/sentiment_lstm.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d053bca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:23:32.819787Z",
     "iopub.status.busy": "2025-05-09T16:23:32.819449Z",
     "iopub.status.idle": "2025-05-09T16:23:32.843591Z",
     "shell.execute_reply": "2025-05-09T16:23:32.842842Z",
     "shell.execute_reply.started": "2025-05-09T16:23:32.819762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/962280390.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/working/sentiment_lstm.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(10002, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/sentiment_lstm.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38c2f9fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:23:32.845481Z",
     "iopub.status.busy": "2025-05-09T16:23:32.845219Z",
     "iopub.status.idle": "2025-05-09T16:23:32.852590Z",
     "shell.execute_reply": "2025-05-09T16:23:32.851676Z",
     "shell.execute_reply.started": "2025-05-09T16:23:32.845462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_and_encode(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z']\", \" \", text).lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    encoded = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "    return torch.tensor(encoded, dtype=torch.long)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    model.eval()\n",
    "    encoded = preprocess_and_encode(text)\n",
    "    length = torch.tensor([len(encoded)])\n",
    "\n",
    "    encoded = encoded.unsqueeze(0).to(device)       # Add batch dim\n",
    "    length = length.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(encoded, length)\n",
    "        prediction = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    reverse_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    return reverse_map[prediction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a08e6062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:24:31.616650Z",
     "iopub.status.busy": "2025-05-09T16:24:31.616297Z",
     "iopub.status.idle": "2025-05-09T16:24:31.624000Z",
     "shell.execute_reply": "2025-05-09T16:24:31.623105Z",
     "shell.execute_reply.started": "2025-05-09T16:24:31.616623Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "text = \"@United your service was AMAZING!! \"\n",
    "print(predict_sentiment(text))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1e467-e021-4dbb-8e2e-d753050fc8b9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 17,
     "sourceId": 742210,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
